1. REORDERING: feasibility and correctness

Let function R represent reordering.
Let G be a graph representing a loop, where each node represents a computation
in the loop, or a live-in value to the loop. A special Phi node selects one of
the inputs dynamically so that for each input of each  computation, there is 
only one source for it. In other words, the graph is in SSA. 
Let LiveIn/Out be the values live into/out of L. 
Reordering transforms the loop as below:
    LiveIn = R(LiveIn)
    G
    Liveout = R'(LiveOut)  //R' is the reverse ordering.
We need to ensure the semantics remains the same. That is, the above is equivalent to
    G
To ensure the semantics is indeed preserved, the following condition is necessary
and sufficient: 
    R must be distributive over any computation in G.
Distributivity means that for a computation C whose inputs are i1, ..., in, 
    R(C(i1, ..., in)) = C(R(i1), ..., R(in))
For example, for the following computation where M is a matrix, and v is a vector: 
    M*v
Reordering 
    R(M*v) = P'*(M*v) = (P'*M*P)*(P'*v) = R(M)*R(v)
where P is a permutation matrix.

Reordering function R is defined as below, assuming the permutation matrix is P: 
    R(x) = P'*x*P  if x is a matrix // P' is conjugate transpose of P
         = P'*x    if x is a vector
         = x       if x is a number
         = error   no other kind of input is accepted.
         
The computations over which reordering is distributive: 
    M*M // R(M*M)=P'*(M*M)*P = (P'*M*P) *(P'*M*P)=R(M)*R(M)
    M+M // R(M+M)=P'*(M+M)*P = P'*M*P + P'*M*P = R(M)+R(M)
    M-M // similar
    M*v // as shown before
    M\v // M*x=v (i.e. x=M\v) is equivalent to (P'*M*P)*(P'x)=P'*v (i.e. R(x)=R(M)\R(v))
    dot(v,v) // R(dot(v,v))=R(v'*v)=v'*v= v'*P*P'*v = (P'*v)' * (P'*v) = dot(R(v), R(v))
    v+v // R(v+v)= P'*(v+v) = (P'*v) + (P'*v) = R(v)+R(v)
    v-v // similar
    n*M // n is a number. R(n*M)=P'*(n*M)*P=n*(P'*M*P)=n*R(M)
    n*v // R(n*v)= P'*(n*v)= n*(P'*v) = n*R(v)
    if(n) // Result of if is a boolean (0: false, 1:true). R(if(n))=R(n!=0)=(R(n)!=0)=if(R(n))
    else  // = if(n==0). Then similar to above
    any other expressions involving only numbers and returning only numbers:
        f(x:<Number):<Number ==> R(f(x)) == f(x) == f(R(x))
    
If reordering is distributive over every computation in the graph, then
R(G) is a graph in which every live-in value is reordered, while all the computation nodes remain
the same. Therefore, to preserve the semantics of the graph, we should reverse reorder the final
results of the graph, i.e., the live out values of the graph.

Over what computations R is NOT distributive: 
    Triangular solver // R would change the rows so that the input matrix is no longer triangular
    Unknown functions

For real field, 
    P' = P.'

Inverse is reorderable in theory, but not for some implementation with assumptions on the shape of the matrix.
For example, inverse of triangular matrix is not reorderable, since that breaks the assumption of
the triangular solver.

Also, read/write/print of a matrix cannot be reordered, because that breaks the expectation of the users.
If we must do so, we need to reverse reorder before the read/write/printing. In general, before acessing
any array element, we must reverse reorder.

Reverse reorder a vector is cheap, since it changes A[i] to A[permute[i]]. So if reverse reordering involves only
a vector, we can make it happen, and then read/write/print it is not an issue any more.

If user requires "bitwise reproducibility", we cannot do reordering either, since floating-point 
operations are not associable.
    
Concept: Inter-dependent Arrays(IA): a set of arrays, including matrices and vectors, that if anyone of them 
is reordered, all the others have to be reordered. In general, for any expression
    c = Op(a, b) 
a, b, and c are inter-dependent. Of course, we do not include scalars among them, if any.
Also, from a, b, and c, we can continue to their subtrees to expand the IA. 
The IA stops when a child is not an array. Thus the concept of maximal IA. 

// For a statement, find a set of subtrees, each being a maximal IA.
FindIA(stmt)
    IAs = {}
    seeds = {stmt}
    while seeds != {}
        seed = get 1 from seeds
        IA = {}
        FindIA(seed, IA, seeds)
        Add IA into IAs

FindIA(currentNode, IA, seeds)
    for each child c of currentNode
        if c is a vector
            if c is a symbol
                IA U= {c}
            elseif c is an expression 
                FindIA(c, IA, seeds)
        else if c is a number
            seeds U= {c}

After IAs are found for all statements in a loop, we can decide the following set:
    reordered = {M} // M is the initially selected matrix to reorder
              = U(IAs(reordered, S)) forall statement S
            IAs(reordered, S) is the union of all IAs in statement S that intersects with reordered

Then 
    reorderedBeforeL = intersect(reordered, headBlock.live_in)
            

***** Initial thoughts about memoizing a reordered matrix into a file, and reusing it from the file:
Optimize a region. A region has a single entry, 1 or more exits. It may have internal
control flow, and thus not necessarily a superblock. At the entry of the region, there
must be a sparse matrix live, which is the initial matrix to reorder. 

Interface is still @acc func()
A typical func() is written in this style, but not necessarily so:
    # Read data from file
    M = MartrixMarket.mm_read(file name)
    
    # Compute 
    .....
    
    # Output
    println(....)
    
For func(), compiler does the following: 
(1) Identify a region. 

First, find the sparse matrix that results in the biggest speedup if reordered. This requires
us to enumerate all sparse matrices, and for each, calculate the benefit from all the operations that 
are directly or indirectly affected by it, and the cost from reordering and reverse reordering 
of all the matrices (including itself), and finally the benifit-cost.

For now, we can simply take the first sparse matrix read from a file, as long as it dominates all exits of the function.
If there is no such a matrix, take the first sparse matrix in the function argument.

Second, find a program point where this sparse matrix is live. We will insert reordering of this matrix,
and may be others, here. Our previous analysis discussed above actually assumes that
a loop entry is such a point.

Third, region formation: grow from the program point to form a region. Our previous analysis discussed above actually assumes
that a loop is a region.

For now, we take only two kinds of program points: (a) the point right after reading a matrix
from a file (to be simple, we further require the point dominates all the exits of the function),
or if there is no such a point, (b) the entry point of the function.

(2) check all statements inside the region is distributive. 
This step can be ignored, if during region formation, every statement has been ensured to be
distributive.

(3) insert reordering  at the region entry, and reverse reordering at each region exit.

If the region entry is right after reading a matrix from a file, then this matrix is the initial 
matrix to be reordered. We can merge the reordering of it with that matrix reading: if a companion 
reordered matrix file exists, read from that file secretely.

The reordered matrix file is already in CSC representation. Thus we can directly construct its
Julia memory representation. Also it contains permutation vector P and P'. All are 1-based.  
